---
title: 并发编程（一）—— 多进程
date: 2019-04-08 21:06:22
categories:
- 技术
tags:
- 计算机系统
- 并发编程
---

之前在[《基于异常控制流的进程协作》]一文中(https://imhuwq.com/2019/03/28/%E5%9F%BA%E4%BA%8E%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81%E5%AE%9E%E7%8E%B0%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%8D%8F%E4%BD%9C/)我们从操作系统和硬件的角度简单分析了单核 CPU 上多进程的并发和协作的**实现机制**。这次我们换个角度，从**使用方式**的角度来看看如何实现并发编程。  
<!--more-->

## 一、回顾进程的概念
进程是操作系统用以在多个运行的程序之间分配资源的基本单元。计算机硬件是没有进程这一概念的，没有进程 CPU 照样可以计算，内存和磁盘照样能存储数据。但是，如果计算机硬件要同时运行多个程序的话，如何分配和管理它的硬件资源就成了一个问题。这时，进程的作用就派上用场了。  
操作系统把每个运行中的程序抽象为一个进程，以进程作为资源分配的基本单元。

### 1.1 对进程分配 CPU 资源
CPU 资源是一种时间资源，对 CPU 资源的分配是时间的分配：操作系统调度 CPU 执行一个进程的指令一段时间后，再执行另一个进程的指令一段时间，以非常快的速度来回切换。从进程的角度来看，它享有整个 CPU 的资源，只是不明白为什么在执行一段时间后总是要停顿一段时间。  
怎么判断某个时间点上 CPU 属于哪个进程呢？主要是看它执行的指令属于哪个进程的指令。CPU 要执行的指令的地址保存在 **PC 寄存器**，但是从指令地址取到指令的内容，依靠 **CR3 寄存器**保存的页表。所以，CPU 在执行哪个进程，主要由 CR3 寄存器决定。  
怎么调度 CPU 资源到另一个进程呢？靠**异常事件**处理流程。CPU 在执行每个指令前，检查寄存器中的状态 Stat，看看是否发生了异常。如果发生了异常，则停止执行当前的指令，由**异常处理程序**决定接下来的走向。  

### 1.2 对进程分配物理内存资源
物理内存空间是一种空间资源，对内存空间的分配不难理解，不异乎指定哪一块区间属于哪一个进程。操作系统为每个进程创建了一个**虚拟页表**用来记录其内存空间在物理内存上的映射关系。  
虚拟页表为每个进程提供了一个**独立**而且**完整**的虚拟内存空间，其寻址范围都是一样的，并且不会由于其它进程的存在而被缩小或被分割，就像程序在单独占有一个完整的物理内存空间一样。  
为了让一个物理内存空间同时满足 N 个程序的内存空间的需求，物理内存空间并没有直接被分配给虚拟内存空间，而是作为虚拟内存的高速缓存。虚拟内存被保存在磁盘上，只有被需要时**按需调度**加载到物理内存，在物理内存空间不足时，选择一些虚拟内存页写回到磁盘。  

### 1.3 对进程分配磁盘资源
程序不直接占有磁盘资源，除非它显示地打开了文件。而每个进程在虚拟内存中拥有一个文件描述符表记录其打开的文件。

### 1.4 进程上下文
进程上下文是进程的一个快照，通过它可以还原一个进程的全貌。进程快照主要包含两方面信息：进程目前的状态(内存和磁盘资源情况)，进程目前的势能(CPU资源情况)。  
进程目前的状态笼统地说就是其内存资源和磁盘资源地使用情况，前者保存在虚拟页表中，后者保存在虚拟内存空间中，找到前者就能间接地找到后者。而虚拟页表，保存在 CPU 的 CR3 寄存器中。  
进程目前的势能其实就是进程的 CPU 资源情况，无外乎就是 CPU 接下来要执行什么指令(PC 寄存器)和要操作的数据是什么(通用寄存器和浮点寄存器)。除此之外，条件码寄存器也很重要，因为它虽然是上一个指令的结果，但是会影响当前指令的计算。  
除了这些“静态”信息之外，还有一些“动态”信息，那些在切出(保存)进程上下文和切入(加载)进程上下文时会被更改或者被处理的数据，比如进程的运行状态(运行/中止/终止)和进程的信号。之所以说它们是动态的，是因为在保存或者恢复进程时，这些数据不是原样保存/加载，而是会根据情况被修改后再保存/修改。  

### 1.5 进程运行模式
大多数时候进程运行在用户模式，执行着程序文件中记录的指令。但是 CPU 遇到异常执行异常处理程序的时候，进程会切换到内核模式。  
用户模式下，进程只能访问属于程序自己的虚拟内存空间，并且要遵守其读写权限。在内核模式下，进程能够访问任何内存位置并任意进行读写，可以实现用户模式实现不了的功能，非常强大，也非常危险。  

## 二、进程的生命周期
### 2.1 创建进程
一般有两种方式创建进程：`execve` 和 `fork`。  
创建一个进程，也就是为其分配资源的过程。这两种创建进程的方式在分配进程资源的行为上有较大的差别：
- CPU 资源：`execve` 分配 CPU 资源到程序的 `main` 函数入口处，`fork` 分配 CPU 资源到调用 `fork` 函数的地方 
- 内存资源：`execve` 删除当前进程的内存空间资源，分配新的内存空间，`fork` 复制(写时复制)当前进程的内存空间
- 磁盘资源：`execve` 虽然会删除当前进程的内存空间，但是会保留其中的磁盘描述符表，`fork` 复制了磁盘描述符表

`execve` 的功能其实更像是“替换”进程，`fork` 才是从当前进程中分裂出来了一个新进程。  
被 `fork` 创建出来的新进程属于当前进程的子进程， `fork` 被调用后返回两次，父进程中返回子进程的 pid，子进程中返回 0。之后两个进程接着 `fork` 之后的指令继续执行，如果想在子进程中执行不同的操作，可以以 `fork` 的返回值作为 flag 来分支：
```c
#include <stdio.h>
#include <sys/types.h>
#include <sys/wait.h>

int main() {
    pid_t pid = fork();
    if (pid == 0) {
        // child process logic
    } else {
        // parent process logic
        pid_t child_pid = waitpid(-1, NULL, 0);
    }
}

```

### 2.2 切换进程
正常情况下 CPU 按照顺序执行进程的指令，但是进程有可能被显示挂起(sleep/paulse)或者隐式挂起(被操作系统调度)，导致进程被切出或者切入：
- 进程被调出，进入内核模式，保存进程上下文，设置进程状态为一种停止状态
- 新进程被调入，加载进程上下文，设置状态为运行状态
- 接受一个信号，进入信号处理程序，如果用户自定义了信号处理函数，以用户模式运行信号处理函数
- 信号处理程序结束，进入用户模式，接着运行进程接下来的指令
- 进程被调出，新进程被调入，如此循环
这里要注意到信号接受和处理的时机：进程从内核模式切换到用户模式之时。这个时机，除了进程被调入时会发生之外，进程完成一次系统调用后也会发生。  

### 2.3 结束进程
当进程发生了错误且尝试修复失败时、进程调用 `exit` 系统调用时和进程执行完毕时，都会结束进程。  
当进程结束时，会进入内核模式把其状态设置为终止状态，给其父进程发送 SIGCHLD 信号，然后调入另一个进程开始执行。  
此时进程虽然已经停止，但是其资源并没有马上被释放，需要父进程来回收。已经停止但是未回收资源的进程被称为僵尸进程。如果进程终止时父进程也终止了，那操作系统会安排 `init` 进程作为其父进程来回收它。需要注意的是，如果进程没有被回收，其虚拟页表将会持续占据内存资源。    

## 三、多进程协作
在回顾了进程的概念和生命周期后，我们再来思考本文的主题：使用多进程来实现并发编程。  
不过我们先想想，为什么需要多进程并发？  
- 首先是多任务机制的要求。一个程序不可能实现所有的任务，所以计算机上必然要运行多个程序。如果选择串行模式的话，一个进程只能在等待另一个进程结束后才能执行，很多功能将无法实现。比如在打开文件浏览器程序浏览文件时，就不能开始执行 word 处理程序
- 其次是加快任务处理的需要。一个 CPU 在一个时刻内只能执行一个进程的指令，反之亦然，一个进程在一个时刻内只能享有一个 CPU 资源。如果计算机硬件上有多个 CPU ，我们就能利用多个进程来使用多个 CPU 的资源

既然有多进程的需求，那就有多进程协作的需求。进程和进程之间如何协作呢？不好意思，我又要咬文嚼字一番了，什么样算是协作？协作就是一个进程告诉另一个进程发生了什么事，然后另一个进程决定如何反应。这其实就是两件事：怎么沟通信息和如何处理信息。  

### 3.1 如何沟通信息
如何沟通信息呢？程序无非就是“输入-处理-输出”的流程，所谓接受信息和发送信息，其实就是在接受输入和产生输出，只不过输入的来源是其它进程的输出，输出的去向是其它进程的输入。但是进程又偏偏给每个程序一个独自享有整个计算机资源的假象，每个进程是感知不到其它进程的，于是对每个进程而言，“其它”进程的输入和输出就成了无稽之谈。  
但是其实还是有机会的，想想看，输入和输出都是保存在内存中的，进程不一定要明确地把信息发送到其它某一个进程中去，只需要多个进程能够**共享读写同样地内存区域**就行了。  
怎么样创建共享的内存区域呢？  
先来看**内核空间**。  
内核空间中最上面的两个页大小的空间是每个进程私有的空间，暂且称为 2P 。虽然 2P 是私有的，但是当其它进程处于内核模式下时，是有读写任意地址的权限的，其中自然包括 2P。而恰好在 2P 空间的最下面保存着进程的 `task_struct`，`task_struct` 又保存着进程的信号位向量。当进程在内核模式下读写这个区域时，就能实现向进程发送**信号**或者接受信号的功能。  
在内核空间的最下面保存着内核代码和数据，暂且把这段区域称为 KN，KN 对所有进程来说都是共享读的。把除去 2P 和 KN 后剩下的区域称为 PP，操作系统提供了 **PIPE** 和 **FIFO** 两种机制来在 PP 中创建共享读写的 Buffer。PIPE 和 FIFO 都被设计成一个 first-in-first-out 的队列，PIPE 只是一个内存 Buffer，而 FIFO 虽然也是一个内存 Buffer，但是被设计为一个文件类型，可以像文件一样打开和读写。除了 PIPE 和 FIFO 外，还有 **Message Queue**(消息队列)这一种机制。Message Queue 和前两种的实现思路是差不多的，都是基于内核空间内存的先进先出队列，只不过 Message Queue 中传递的数据不再是字节(byte)，而是一个特定类型的数据(byte package, message)。  
再来看**用户空间**。  
使用 **`mmap`** 可以把文件映射到内存区域中，并且可以指定映射方式为共享的。如果两个进程对同一个文件使用共享的映射方式的话，两个进程就共享了这些内存区域。`mmap` 可以映射一个真实的磁盘文件，也可以映射一个匿名文件。匿名文件和 FIFO 一样也是一个内存中文件，不过它处于用户空间，而 FIFO 处于内核空间。除了匿名文件，还有一个基于用户内存空间的文件系统，叫 **`shm`** 文件系统。基于 `shm` 文件系统有 System V 共享内存机制。  
怎么样告知其它进程一段内存区域是共享的呢？ 
`task_struct` 中的信号由操作系统内核在内核模式中自动读和写，所以不用担心。  
FIFO、mmap 非匿名文件、shm 都使用到了具体的文件路径/ID，所以多进程中可以通过相同的文件名来获取共享内存区，也可以通过 `fork` 和 `execve` 继承的文件描述符表来获取共享内存区域。  
通过 PIPE、mmap 匿名文件和 Message Queue 创建的共享内存区域，只有通过这些函数调用的返回值)(指针或者文件描述符)才能获取到，而这些返回值保存在进程的虚拟内存空间中，只有通过 `fork` 和 `execv` 复制父进程的虚拟内存空间才能获取到。  

### 3.1 如何处理信息
如何发送和接受信息呢？  
程序可以用 `kill` 系统调用向指定进程发送信号，但是并没有接受信号的系统调用，因为发送信号和接受信号是同时发生的(此处接受信号并不等于处理信号)。PIPE 和 FIFO 队列使用 `read` 和 `write` 系统调用来接受和发送信息，Message Queue 使用 `msgsnd` 和 `msgrcv` 系统调用来发送和接受消息。mmap 和 shm 直接使用指针地址读写。  
发送消息总比接受接受消息要简单，因为发送消息总是即时的，但是接受新消息却需要程序主动去检查或者被通知才能知道。在接受到新消息前，程序是**异步**地执行其它指令，还是**阻塞**着直到新消息到来呢？  
信号处理机制总是异步的，除非通过 `waitpid` 显示地阻塞当前进程并等待子进程的 `SICHLD` 信号。进程从内核模式切换到用户模式之际，会自动检查接受到地信号并进行处理。而这样地时机，一般发生在进程刚刚被调入 CPU 开始执行时，或着进程刚刚完成一次系统调用并返回时。程序可以用 `signal` 来为信号注册优先的处理函数，如果没有注册，则调用默认的信号处理程序。    
三种队列总是阻塞的，当队列满时会阻塞写，当队列空时会阻塞读。  
使用 mmap 或者 shm 的话，就没有操作系统提供的异步或者阻塞机制，只能由程序自己来实现。  

## 四、多进程协作 API

## 五、总结
